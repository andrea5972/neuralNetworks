{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern Art: ARTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Reshape, Conv2D, Conv2DTranspose, Flatten, Dropout\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# generator\n",
    "generator_input = Input(shape=(latent_dim,))\n",
    "\n",
    "x = Dense(128 * 16 * 16)(generator_input)\n",
    "x = LeakyReLU()(x)\n",
    "x = Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = Conv2D(256, 5, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(256, 5, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(256, 5, padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = Model(inputs=generator_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# discriminator\n",
    "disc_input = Input(shape=(height, width, channels))\n",
    "x = Conv2D(128, 3)(disc_input)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128, 4, strides=2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128, 4, strides=2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Conv2D(128, 4, strides=2)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = Model(inputs=disc_input, outputs=x)\n",
    "\n",
    "disc_opt = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=disc_opt, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "\n",
    "gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(X_train, y_train), (_, _) = cifar10.load_data()\n",
    "X_train = X_train[y_train.flatten() == 6]  \n",
    "X_train = X_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "discriminator loss: 0.70526505\n",
      "adversarial loss: 0.7005836\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "batch_size = 20\n",
    "save_dir = './Star_date'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = X_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    \n",
    "    # train discriminator\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    # train generator\n",
    "    misleading_targets = np.zeros((batch_size, 1))  \n",
    "    a_loss = gan.train_on_batch(random_latent_vectors,\n",
    "                               misleading_targets)  \n",
    "    start += batch_size\n",
    "    if start > len(X_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.1')\n",
    "        \n",
    "        print('discriminator loss:', d_loss)\n",
    "        print('adversarial loss:', a_loss)\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255, scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_image' + str(step) + '.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255, scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_image' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(16, 6)\n",
    "plt.imshow(plt.imread('./Star_date/generated_image0.png'))\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(plt.imread('./Star_date/real_image0.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.array_to_img(generated_images[1] * 255, scale=False)\n",
    "img.save(os.path.join(save_dir, 'generated_image' + str(step) + '.png'))\n",
    "        \n",
    "img = image.array_to_img(real_images[1] * 255, scale=False)\n",
    "img.save(os.path.join(save_dir, 'real_image' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(16, 6)\n",
    "plt.imshow(plt.imread('./Star_date/generated_image99.png'))\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(plt.imread('./Star_date/real_image99.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
